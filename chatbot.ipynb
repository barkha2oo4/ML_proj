{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxYRJIYm3GqS",
        "outputId": "b911ff61-46ed-4bee-f8ba-63a1e3f9f5ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n"
          ]
        }
      ],
      "source": [
        "pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAvaT7_64A9A",
        "outputId": "35c924cd-d9c3-4fd8-8381-24e873894485"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hi, I'm a chatbot. Let's chat!\n",
            "Hey how can I help you?\n",
            "I don't have an age.\n",
            "You can check your device's clock.\n",
            "None\n",
            "I exist in the cloud.\n",
            "None\n",
            "Glad I could help!\n",
            "Have a nice day!\n",
            "See you later!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.chat.util import Chat,reflections\n",
        "pairs=[(r\"hi|hello|hey\", [\"Hello!\",\"Hi there!\",\"Hey how can I help you?\"]),(r\"how are you?\",[\"I'm doing great\"]),(r\"what is your name?\", [\"My name is ChatBot.\", \"You can call me Bot.\"]),\n",
        "    (r\"what do you do?\", [\"I'm here to chat with you.\", \"I can answer your questions.\"]),\n",
        "    (r\"how old are you?\", [\"I'm still under development.\", \"I don't have an age.\"]),\n",
        "    (r\"where are you from?\", [\"I'm from the digital world.\", \"I exist in the cloud.\"]),\n",
        "    (r\"what is your favorite color?\", [\"I don't have a favorite color.\", \"I like all colors.\"]),\n",
        "    (r\"tell me a joke\", [\"Why don't scientists trust atoms? Because they make up everything!\"]),\n",
        "    (r\"what is the weather like?\", [\"I don't have access to real-time information.\", \"You can check a weather app for that.\"]),\n",
        "    (r\"what time is it?\", [\"I don't have access to real-time information.\", \"You can check your device's clock.\"]),\n",
        "    (r\"goodbye|bye\", [\"Goodbye!\", \"See you later!\", \"Have a nice day!\"]),\n",
        "    (r\"thank you|thanks\", [\"You're welcome!\", \"No problem!\", \"Glad I could help!\"]),\n",
        "       ]\n",
        "\n",
        "def chatbot():\n",
        "    print(\"Hi, I'm a chatbot. Let's chat!\")\n",
        "    chat = Chat(pairs, reflections)\n",
        "    chat.converse()\n",
        "\n",
        "# Start the chatbot\n",
        "chatbot()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BrvRAdXuL8pT"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install torch\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "# Load the pre-trained GPT-2 model and tokenizer\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "\n",
        "# Function to generate text based on user input\n",
        "def generate_response(prompt):\n",
        "    # Encode the input prompt and generate a response\n",
        "    inputs = tokenizer.encode(prompt, return_tensors='pt')\n",
        "    outputs = model.generate(inputs, max_length=150, num_return_sequences=1, no_repeat_ngram_size=2)\n",
        "\n",
        "    # Decode and return the generated response\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return response\n",
        "\n",
        "# Chatbot interaction loop\n",
        "def chatbot():\n",
        "    print(\"Hi! I'm an advanced GPT-2 chatbot. Type 'quit' to exit.\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() == 'quit': # Check if user wants to exit\n",
        "            print(\"Chatbot: Goodbye!\")\n",
        "            break\n",
        "        else:\n",
        "            response = generate_response(user_input)\n",
        "            print(f\"Chatbot: {response}\")\n",
        "\n",
        "# Run the chatbot\n",
        "chatbot()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}